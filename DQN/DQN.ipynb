{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL_JaneStreet_dataset_Popov.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "5DZ3gyVks5jf",
        "LJCrK-Dbs0KY"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuyLRb3SRVGz",
        "outputId": "1d6bd1cd-3899-4e92-eb39-a6fac0bb36d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "metadata": {
        "id": "0MtwkyWTSkpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jMkYda7KTJp",
        "outputId": "db340a70-8902-4e3b-f8dc-45127e2661f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Projects/Project_inf_571\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/Projects/Project_inf_571"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2x4jg00lkr9",
        "outputId": "b71e6c40-2f31-41db-efdc-9942707fa190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoints  dqn.py\tdqn_v7.pt  q_for_dqn_v1.pt\t\t train.parquet\n",
            "DoubleDQN    dqn_v1.pt\tproject    RL_for_JaneStreet_Data.ipynb  VanillaDQN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "execution": {
          "iopub.execute_input": "2021-01-13T05:46:36.252443Z",
          "iopub.status.busy": "2021-01-13T05:46:36.251719Z",
          "iopub.status.idle": "2021-01-13T05:46:37.693315Z",
          "shell.execute_reply": "2021-01-13T05:46:37.692714Z"
        },
        "papermill": {
          "duration": 1.463638,
          "end_time": "2021-01-13T05:46:37.693437",
          "exception": false,
          "start_time": "2021-01-13T05:46:36.229799",
          "status": "completed"
        },
        "tags": [],
        "id": "LLfzbOW2R4b-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F \n",
        "import torch.optim as optim \n",
        "from torch.distributions import Categorical\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import copy\n",
        "import fastprogress\n",
        "\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "metadata": {
        "id": "N8sO2_wucNUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.014661,
          "end_time": "2021-01-13T05:46:38.110129",
          "exception": false,
          "start_time": "2021-01-13T05:46:38.095468",
          "status": "completed"
        },
        "tags": [],
        "id": "KXGzEE3MR4cC"
      },
      "source": [
        "# Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-13T05:46:38.144385Z",
          "iopub.status.busy": "2021-01-13T05:46:38.143617Z",
          "iopub.status.idle": "2021-01-13T05:46:38.146677Z",
          "shell.execute_reply": "2021-01-13T05:46:38.146196Z"
        },
        "papermill": {
          "duration": 0.021764,
          "end_time": "2021-01-13T05:46:38.146781",
          "exception": false,
          "start_time": "2021-01-13T05:46:38.125017",
          "status": "completed"
        },
        "tags": [],
        "id": "OqNHs3R9R4cD"
      },
      "outputs": [],
      "source": [
        "path = './train.parquet'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-13T05:46:38.183708Z",
          "iopub.status.busy": "2021-01-13T05:46:38.183102Z",
          "iopub.status.idle": "2021-01-13T05:48:48.432069Z",
          "shell.execute_reply": "2021-01-13T05:48:48.431083Z"
        },
        "papermill": {
          "duration": 130.270653,
          "end_time": "2021-01-13T05:48:48.432238",
          "exception": false,
          "start_time": "2021-01-13T05:46:38.161585",
          "status": "completed"
        },
        "tags": [],
        "id": "RePGNfkPR4cE"
      },
      "outputs": [],
      "source": [
        "def load_df(path, \n",
        "            # device\n",
        "            ):\n",
        "    # if device == 'cuda':\n",
        "    #     df = cudf.read_csv(path)\n",
        "    # else:\n",
        "    #     df = pd.read_csv(path)\n",
        "    df = pd.read_parquet(path)\n",
        "        \n",
        "    features = [column for column in df.columns if 'feature' in column]\n",
        "    \n",
        "    return df, features\n",
        "\n",
        "\n",
        "# load data and features\n",
        "df, features = load_df(path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBBhb7tdctlL",
        "outputId": "71696e53-58ef-4e58-8f83-16a938b5db4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2390491, 138)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhOPemNkc37M",
        "outputId": "eb74a734-8b0d-4703-87c2-a945365e77d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "130"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run this if you want to train agent\n",
        "- delete rows with weight == 0\n",
        "- normalize features\n",
        "- add ground truth action"
      ],
      "metadata": {
        "id": "RAuzDydFOXht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_actions(df, features):\n",
        "    f_mean = df[features[1:]].mean()\n",
        "    f_std = df[features[1:]].std()\n",
        "    \n",
        "    # delete all trading oportunities that are not taken into account for \n",
        "    # utility score calculation\n",
        "    df = df.query('weight > 0').reset_index(drop = True)\n",
        "\n",
        "    # normalize each feature\n",
        "    df[features[1:]] = df[features[1:]].fillna(f_mean)\n",
        "    df[features[1:]] = (df[features[1:]] - f_mean) / f_std\n",
        "\n",
        "    # add the correct action that should be chosen for each trading oportunity\n",
        "    df['action'] = (df['resp'] > 0).astype('int')\n",
        "    return df\n",
        "\n",
        "\n",
        "# add the action column\n",
        "df = add_actions(df, features)"
      ],
      "metadata": {
        "id": "o7oS7Tk4OWcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.015482,
          "end_time": "2021-01-13T05:49:01.000543",
          "exception": false,
          "start_time": "2021-01-13T05:49:00.985061",
          "status": "completed"
        },
        "tags": [],
        "id": "5Py-cu5nR4cI"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-13T05:49:01.044274Z",
          "iopub.status.busy": "2021-01-13T05:49:01.043428Z",
          "iopub.status.idle": "2021-01-13T05:49:01.045814Z",
          "shell.execute_reply": "2021-01-13T05:49:01.046297Z"
        },
        "papermill": {
          "duration": 0.030566,
          "end_time": "2021-01-13T05:49:01.046426",
          "exception": false,
          "start_time": "2021-01-13T05:49:01.015860",
          "status": "completed"
        },
        "tags": [],
        "id": "MtVbhY9uR4cJ"
      },
      "outputs": [],
      "source": [
        "class Env:\n",
        "    def __init__(self, df, features):\n",
        "        self.n_samples = df.shape[0]\n",
        "        self.weight = torch.FloatTensor(df['weight'].values)\n",
        "        self.resp = torch.FloatTensor(df['resp'].values)\n",
        "        self.states = torch.FloatTensor(df[features].values)\n",
        "        self.observation_space = df[features].shape[1]\n",
        "        self.action_space = 2\n",
        "        self.idx = 0\n",
        "        \n",
        "    def reset(self):\n",
        "        self.idx = 0\n",
        "        return self.states[self.idx].view(1, -1)\n",
        "    \n",
        "    def step(self, action):\n",
        "        reward = self.weight[self.idx] * self.resp[self.idx] * action\n",
        "        self.idx += 1\n",
        "        if self.idx >= self.n_samples:\n",
        "            done = True\n",
        "            self.idx = 0\n",
        "        else:\n",
        "            done = False\n",
        "        info = 0\n",
        "        return self.states[self.idx].view(1, -1), reward, done, info"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.015101,
          "end_time": "2021-01-13T05:49:01.076784",
          "exception": false,
          "start_time": "2021-01-13T05:49:01.061683",
          "status": "completed"
        },
        "tags": [],
        "id": "k-WxsblhR4cK"
      },
      "source": [
        "# Configurations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-13T05:49:01.117378Z",
          "iopub.status.busy": "2021-01-13T05:49:01.116506Z",
          "iopub.status.idle": "2021-01-13T05:49:01.118699Z",
          "shell.execute_reply": "2021-01-13T05:49:01.119270Z"
        },
        "papermill": {
          "duration": 0.02704,
          "end_time": "2021-01-13T05:49:01.119392",
          "exception": false,
          "start_time": "2021-01-13T05:49:01.092352",
          "status": "completed"
        },
        "tags": [],
        "id": "6MaEnufBR4cL"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    def __init__(self, \n",
        "                 version = 0,\n",
        "                 epsilon_start = 1.,\n",
        "                 epsilon_final = 0.01,\n",
        "                 epsilon_decay = 8000,\n",
        "                 gamma = 0.99, \n",
        "                 lr = 1e-4, \n",
        "                 target_net_update_freq = 1000, \n",
        "                 memory_size = 100000, \n",
        "                 batch_size = 128, \n",
        "                 learning_starts = 5000,\n",
        "                 max_frames = 10000000): \n",
        "\n",
        "        self.version = version\n",
        "        self.epsilon_start = epsilon_start\n",
        "        self.epsilon_final = epsilon_final\n",
        "        self.epsilon_decay = epsilon_decay\n",
        "        self.epsilon_by_frame = lambda i: self.epsilon_final + (self.epsilon_start - self.epsilon_final) * np.exp(-1. * i / self.epsilon_decay)\n",
        "\n",
        "        self.gamma =gamma\n",
        "        self.lr =lr\n",
        "\n",
        "        self.target_net_update_freq =target_net_update_freq\n",
        "        self.memory_size =memory_size\n",
        "        self.batch_size =batch_size\n",
        "\n",
        "        self.learning_starts = learning_starts\n",
        "        self.max_frames = max_frames"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.015184,
          "end_time": "2021-01-13T05:49:01.149910",
          "exception": false,
          "start_time": "2021-01-13T05:49:01.134726",
          "status": "completed"
        },
        "tags": [],
        "id": "6nvYUZpnR4cM"
      },
      "source": [
        "# Experience Replay (run for training)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-13T05:49:01.193013Z",
          "iopub.status.busy": "2021-01-13T05:49:01.192141Z",
          "iopub.status.idle": "2021-01-13T05:49:01.194765Z",
          "shell.execute_reply": "2021-01-13T05:49:01.195282Z"
        },
        "papermill": {
          "duration": 0.02988,
          "end_time": "2021-01-13T05:49:01.195406",
          "exception": false,
          "start_time": "2021-01-13T05:49:01.165526",
          "status": "completed"
        },
        "tags": [],
        "id": "81_J1lRMR4cN"
      },
      "outputs": [],
      "source": [
        "class ExperienceReplay:\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "\n",
        "    def push(self, transition):\n",
        "        self.memory.append(transition)\n",
        "        if len(self.memory) > self.capacity:\n",
        "            del self.memory[0]\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        batch = random.sample(self.memory, batch_size)\n",
        "        \n",
        "        states = []\n",
        "        actions = []\n",
        "        rewards = []\n",
        "        next_states = [] \n",
        "        dones = []\n",
        "\n",
        "        for b in batch: \n",
        "            states.append(b[0])\n",
        "            actions.append(b[1])\n",
        "            rewards.append(b[2])\n",
        "            next_states.append(b[3])\n",
        "            dones.append(b[4])\n",
        "\n",
        "        return states, actions, rewards, next_states, dones\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DQN"
      ],
      "metadata": {
        "id": "Wp5v94O7bXwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Qmodel(nn.Module): \n",
        "    def __init__(self, obs, ac): \n",
        "        super().__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(obs, 512),\n",
        "            nn.ReLU(), \n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(256, ac),\n",
        "        )\n",
        "\n",
        "    def forward(self, x): \n",
        "        out = self.model(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "TQK2k337goJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DoubleDQN(nn.Module): \n",
        "    def __init__(self, obs, ac, config): \n",
        "        super().__init__()\n",
        "\n",
        "        self.q = Qmodel(obs, ac).to(device)\n",
        "        self.target = Qmodel(obs, ac).to(device)\n",
        "            \n",
        "        self.target.load_state_dict(self.q.state_dict())\n",
        "        self.target.eval()\n",
        "\n",
        "        self.target_net_update_freq = config.target_net_update_freq\n",
        "        self.update_counter = 0\n",
        "\n",
        "    def get_action(self, x):\n",
        "        self.q.eval()\n",
        "        x = torch.FloatTensor(x).to(device).view(-1, 130)\n",
        "        with torch.no_grad(): \n",
        "            a = self.q(x).max(1)[1]\n",
        "        self.q.train()\n",
        "        if len(x) > 1:\n",
        "            return a.detach().cpu().numpy()\n",
        "        return a.item()\n",
        "\n",
        "    def update_policy(self, adam, memory, params): \n",
        "        b_states, b_actions, b_rewards, b_next_states, b_masks = \\\n",
        "            memory.sample(params.batch_size)\n",
        "\n",
        "        states = torch.FloatTensor(b_states).to(device)\n",
        "        actions = torch.LongTensor(b_actions).reshape(-1,1).to(device)\n",
        "        rewards = torch.FloatTensor(b_rewards).reshape(-1,1).to(device)\n",
        "        next_states = torch.FloatTensor(b_next_states).to(device)\n",
        "        masks = torch.FloatTensor(b_masks).reshape(-1,1).to(device)\n",
        "\n",
        "        current_q_values = self.q(states).gather(1, actions)\n",
        "        with torch.no_grad():\n",
        "            max_next_q_vals = self.target(next_states).max(1)[0].reshape(-1,1)\n",
        "        expected_q_vals = rewards + max_next_q_vals * 0.99 * masks\n",
        "        loss = F.mse_loss(expected_q_vals, current_q_values)\n",
        "\n",
        "        adam.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        for p in self.q.parameters(): \n",
        "            p.grad.data.clamp_(-1.,1.)\n",
        "        adam.step()\n",
        "\n",
        "        self.update_counter += 1\n",
        "        if self.update_counter % self.target_net_update_freq == 0: \n",
        "            self.update_counter = 0 \n",
        "            self.target.load_state_dict(self.q.state_dict())\n",
        "            self.target.eval()"
      ],
      "metadata": {
        "id": "NBi7VuzzQMnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.015654,
          "end_time": "2021-01-13T05:49:01.387141",
          "exception": false,
          "start_time": "2021-01-13T05:49:01.371487",
          "status": "completed"
        },
        "tags": [],
        "id": "Vwy78j3ZR4cQ"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = df.shape[0]\n",
        "df_train = df[:int(0.9 * n_samples)]\n",
        "df_test = df[int(0.9 * n_samples):int(0.95 * n_samples)]\n",
        "df_valid = df[int(0.95 * n_samples):]"
      ],
      "metadata": {
        "id": "b7JEXOuroO4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-13T05:49:01.437979Z",
          "iopub.status.busy": "2021-01-13T05:49:01.437156Z",
          "iopub.status.idle": "2021-01-13T05:49:07.717187Z",
          "shell.execute_reply": "2021-01-13T05:49:07.715896Z"
        },
        "papermill": {
          "duration": 6.314318,
          "end_time": "2021-01-13T05:49:07.717327",
          "exception": false,
          "start_time": "2021-01-13T05:49:01.403009",
          "status": "completed"
        },
        "tags": [],
        "id": "m2XvyrGmR4cQ"
      },
      "outputs": [],
      "source": [
        "env = Env(df_train, features)\n",
        "\n",
        "config = Config(version = 7,\n",
        "                epsilon_start = 1.,\n",
        "                epsilon_final = 0.01,\n",
        "                epsilon_decay = 8000,\n",
        "                gamma = 0.99, \n",
        "                lr = 1e-3, \n",
        "                target_net_update_freq = 1000, \n",
        "                memory_size = env.n_samples // 100, \n",
        "                batch_size = 128, \n",
        "                learning_starts = 1000,\n",
        "                max_frames = env.n_samples)\n",
        "\n",
        "agent = DoubleDQN(env.observation_space, env.action_space, config)\n",
        "\n",
        "memory = ExperienceReplay(config.memory_size)\n",
        "\n",
        "adam = optim.Adam(agent.q.parameters(), lr = config.lr) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2021-01-13T05:49:07.803959Z",
          "iopub.status.busy": "2021-01-13T05:49:07.803115Z",
          "iopub.status.idle": "2021-01-13T10:02:13.538067Z",
          "shell.execute_reply": "2021-01-13T10:02:13.538562Z"
        },
        "papermill": {
          "duration": 15185.804898,
          "end_time": "2021-01-13T10:02:13.538730",
          "exception": false,
          "start_time": "2021-01-13T05:49:07.733832",
          "status": "completed"
        },
        "tags": [],
        "id": "BsPEnxpsR4cR"
      },
      "outputs": [],
      "source": [
        "n_episodes = 5 # aka epoches\n",
        "# ep_reward for epoches\n",
        "recap = []\n",
        "\n",
        "for episode in range(n_episodes):\n",
        "    print('Episode №', episode)    \n",
        "    s = env.reset()\n",
        "    # cumulative reward per epoche (sum of resps for all rows in train set \n",
        "    # depending on the agents actions) \n",
        "    ep_reward = 0. \n",
        "    # ep_reward for after each 1000 rows in train set\n",
        "    rewards = []\n",
        "\n",
        "    p_bar = tqdm(total = config.max_frames)\n",
        "    for frame in range(config.max_frames):\n",
        "        epsilon = config.epsilon_by_frame(frame)\n",
        "        # epsilon greedy action choise with decreasing temperature\n",
        "        if np.random.random() > epsilon: \n",
        "            action = agent.get_action(s)\n",
        "        else: \n",
        "            action = np.random.randint(0, env.action_space)\n",
        "        ns, r, ns_is_the_first_frame_now, _ = env.step(action)\n",
        "        ep_reward += r\n",
        "        if (frame + 1) % 1000 == 0 or frame == config.max_frames-1:\n",
        "            print(f'{frame + 1}/{config.max_frames}:', ep_reward, end = '\\r')\n",
        "            rewards.append(ep_reward.item())\n",
        "        if ns_is_the_first_frame_now:\n",
        "            recap.append(ep_reward.item())\n",
        "            p_bar.set_description('Rew: {:.3f}'.format(ep_reward))\n",
        "            with open(f'rewards_ep{episode}.pkl', 'wb') as f:\n",
        "                pickle.dump(rewards, f)\n",
        "            torch.save(agent.state_dict(), f'./checkpoints/dqn_v{config.version}_ep{episode}.pt')\n",
        "        # mask = 0 if its_the_transition_from_last_to_first_row else 1\n",
        "        memory.push((s.reshape(-1).numpy().tolist(), action, r, \n",
        "            ns.reshape(-1).numpy().tolist(), 0. if ns_is_the_first_frame_now else 1.))\n",
        "        s = ns  \n",
        "        p_bar.update(1)\n",
        "        if episode > 0: \n",
        "            agent.update_policy(adam, memory, config)\n",
        "        elif frame > config.learning_starts:\n",
        "            agent.update_policy(adam, memory, config)\n",
        "    p_bar.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(f'recap_ep{episode}.pkl', 'wb') as f:\n",
        "    pickle.dump(recap, f)"
      ],
      "metadata": {
        "id": "776P-8GLLci1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.704212,
          "end_time": "2021-01-13T10:02:15.012403",
          "exception": false,
          "start_time": "2021-01-13T10:02:14.308191",
          "status": "completed"
        },
        "tags": [],
        "id": "3LJNO14QR4cS"
      },
      "source": [
        "# Assess and compare models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_samples = df.shape[0]\n",
        "df_train = df[:int(0.9 * n_samples)]\n",
        "df_test = df[int(0.9 * n_samples):int(0.95 * n_samples)]\n",
        "df_valid = df[int(0.95 * n_samples):]"
      ],
      "metadata": {
        "id": "CeuwEhnMNVbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility scores"
      ],
      "metadata": {
        "id": "5DZ3gyVks5jf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def utility_score(df, action):\n",
        "    weight = df['weight'].values\n",
        "    resp = df['resp'].values\n",
        "    date = df['date'].values\n",
        "    count_i = len(np.unique(date))\n",
        "    Pi = np.bincount(date, weight * resp * action)\n",
        "    t = np.sum(Pi) / np.sqrt(np.sum(Pi ** 2)) * np.sqrt(250 / count_i)\n",
        "    u = np.clip(t, 0, 6) * np.sum(Pi)\n",
        "    return u"
      ],
      "metadata": {
        "id": "jMA848vZtGyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "v1"
      ],
      "metadata": {
        "id": "BHm-egU-s76b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CHANGE THIS\n",
        "version = 1\n",
        "\n",
        "# does not matter\n",
        "env = Env(df_test, features)   \n",
        "# does not matter\n",
        "config = Config(epsilon_start = 1.,\n",
        "                epsilon_final = 0.01,\n",
        "                epsilon_decay = 8000,\n",
        "                gamma = 0.99, \n",
        "                lr = 1e-4, \n",
        "                target_net_update_freq = 1000, \n",
        "                memory_size = env.n_samples // 100, \n",
        "                batch_size = 128, \n",
        "                learning_starts = 5000,\n",
        "                max_frames = env.n_samples)\n",
        "agent = DoubleDQN(env.observation_space, env.action_space, config)\n",
        "PATH = f'./dqn_v{version}.pt'\n",
        "agent.load_state_dict(torch.load(PATH, map_location=torch.device('cpu')))\n",
        "agent.eval()\n",
        "\n",
        "# CHANGE THIS\n",
        "assess_df = df_valid\n",
        "states = assess_df[features].values\n",
        "with torch.no_grad():\n",
        "    actions = agent.get_action(states)\n",
        "print(f'For config v{version}:')\n",
        "print('% of ones for val split = ', sum(actions)/len(actions))\n",
        "# for config v7\n",
        "print('Utility score on val = ', utility_score(assess_df, np.array(actions)))"
      ],
      "metadata": {
        "id": "et6odSkxQZHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "v0"
      ],
      "metadata": {
        "id": "dx0wZlUntBi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CHANGE THIS\n",
        "version = 0\n",
        "# does not matter\n",
        "env = Env(df_test, features)   \n",
        "# does not matter\n",
        "config = Config(epsilon_start = 1.,\n",
        "                epsilon_final = 0.01,\n",
        "                epsilon_decay = 8000,\n",
        "                gamma = 0.99, \n",
        "                lr = 1e-4, \n",
        "                target_net_update_freq = 1000, \n",
        "                memory_size = env.n_samples // 100, \n",
        "                batch_size = 128, \n",
        "                learning_starts = 5000,\n",
        "                max_frames = env.n_samples)\n",
        "agent = DoubleDQN(env.observation_space, env.action_space, config)\n",
        "# CHANGE THIS\n",
        "PATH = f'./dqn_v{version}.pt'\n",
        "agent.load_state_dict(torch.load(PATH, map_location=torch.device('cpu')))\n",
        "agent.eval()\n",
        "\n",
        "# CHANGE THIS\n",
        "assess_df = df_test\n",
        "states = assess_df[features].values\n",
        "with torch.no_grad():\n",
        "    actions = agent.get_action(states)\n",
        "\n",
        "print(f'For config v{version}:')\n",
        "print('% of ones for test split = ', sum(actions)/len(actions))\n",
        "# for config v7\n",
        "print('Utility score = ', utility_score(assess_df, np.array(actions)))"
      ],
      "metadata": {
        "id": "dp4q1f7InWrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## plot cumulative reward"
      ],
      "metadata": {
        "id": "LJCrK-Dbs0KY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = env.reset()\n",
        "ep_reward = 0. \n",
        "# ep_reward for after each 1000 rows in train set\n",
        "rewards = []\n",
        "\n",
        "for frame in range(assess_df.shape[0]):\n",
        "    # epsilon = config.epsilon_by_frame(frame)\n",
        "\n",
        "    # if np.random.random() > epsilon: \n",
        "    #     action = agent.get_action(s)\n",
        "    # else: \n",
        "    #     action = np.random.randint(0, env.action_space)\n",
        "    action = agent.get_action(s)\n",
        "\n",
        "    print()\n",
        "    ns, r, done, infos = env.step(action)\n",
        "\n",
        "    try:\n",
        "        ep_reward += r \n",
        "    except Exception as e:\n",
        "        print(str(e))\n",
        "        print()\n",
        "        print(action, ns, r, done, infos)\n",
        "        break\n",
        "\n",
        "    if done:\n",
        "        ns = env.reset()\n",
        "        ep_reward = 0.\n",
        "\n",
        "    s = ns  \n",
        "    if (frame + 1) % 1000 == 0:\n",
        "        print(f'{frame + 1}/{config.max_frames}:', ep_reward, end = '\\r')\n",
        "        rewards.append(ep_reward.item())"
      ],
      "metadata": {
        "id": "jzZosuH0VK1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.title(\"Rewards per Episode in test\")\n",
        "plt.plot(rewards)\n",
        "plt.xlabel(\"Episode\")\n",
        "plt.ylabel(\"Reward\")"
      ],
      "metadata": {
        "id": "xWzDRTW7ZLv0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}